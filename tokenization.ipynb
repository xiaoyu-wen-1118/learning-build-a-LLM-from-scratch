{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20479\n",
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no great surprise to me to hear that, in the height of\n"
     ]
    }
   ],
   "source": [
    "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "print(len(raw_text))\n",
    "print(raw_text[:150])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', '', 'world', '', 'This', '', 'is', 'a', 'test', '']\n"
     ]
    }
   ],
   "source": [
    "text = \"Hello, world. This, is a test.\"\n",
    "print(re.split(r\"[,.|\\s]\", text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', raw_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The \n",
    "\n",
    "re.split()\n",
    "\n",
    " function is used to split the \n",
    "\n",
    "raw_text\n",
    "\n",
    " string wherever the pattern specified in the regular expression is found. The regular expression pattern `r\"[,.:;?_!()\\']|--|\\s\"` includes several delimiters:\n",
    "- `[,.:;?_!()\\']` matches any single character within the square brackets, such as commas, periods, colons, semicolons, question marks, underscores, exclamation marks, parentheses, and single quotes.\n",
    "- `|--` matches the double hyphen (`--`).\n",
    "- `|\\s` matches any whitespace character, including spaces, tabs, and newlines.\n",
    "\n",
    "By using this pattern, the \n",
    "\n",
    "re.split()\n",
    "\n",
    " function will break the \n",
    "\n",
    "raw_text\n",
    "\n",
    " into tokens whenever it encounters any of these delimiters. The result is stored in the variable \n",
    "\n",
    "preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed = [item.strip() for item in preprocessed if item.strip()] # if item.strip() removes empty strings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4690\n",
      "['I', 'HAD', 'always', 'thought', 'Jack', 'Gisburn', 'rather', 'a', 'cheap', 'genius', '--', 'though', 'a', 'good', 'fellow', 'enough', '--', 'so', 'it', 'was', 'no', 'great', 'surprise', 'to', 'me', 'to', 'hear', 'that', ',', 'in']\n"
     ]
    }
   ],
   "source": [
    "print(len(preprocessed))\n",
    "print(preprocessed[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['!',\n",
       " '\"',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " ',',\n",
       " '--',\n",
       " '.',\n",
       " ':',\n",
       " ';',\n",
       " '?',\n",
       " 'A',\n",
       " 'Ah',\n",
       " 'Among',\n",
       " 'And',\n",
       " 'Are',\n",
       " 'Arrt',\n",
       " 'As',\n",
       " 'At',\n",
       " 'Be',\n",
       " 'Begin',\n",
       " 'Burlington',\n",
       " 'But',\n",
       " 'By',\n",
       " 'Carlo',\n",
       " 'Chicago',\n",
       " 'Claude',\n",
       " 'Come',\n",
       " 'Croft',\n",
       " 'Destroyed',\n",
       " 'Devonshire',\n",
       " 'Don',\n",
       " 'Dubarry',\n",
       " 'Emperors',\n",
       " 'Florence',\n",
       " 'For',\n",
       " 'Gallery',\n",
       " 'Gideon',\n",
       " 'Gisburn',\n",
       " 'Gisburns',\n",
       " 'Grafton',\n",
       " 'Greek',\n",
       " 'Grindle',\n",
       " 'Grindles',\n",
       " 'HAD',\n",
       " 'Had',\n",
       " 'Hang',\n",
       " 'Has',\n",
       " 'He',\n",
       " 'Her',\n",
       " 'Hermia',\n",
       " 'His',\n",
       " 'How',\n",
       " 'I',\n",
       " 'If',\n",
       " 'In',\n",
       " 'It',\n",
       " 'Jack',\n",
       " 'Jove',\n",
       " 'Just',\n",
       " 'Lord',\n",
       " 'Made',\n",
       " 'Miss',\n",
       " 'Money',\n",
       " 'Monte',\n",
       " 'Moon-dancers',\n",
       " 'Mr',\n",
       " 'Mrs',\n",
       " 'My',\n",
       " 'Never',\n",
       " 'No',\n",
       " 'Now',\n",
       " 'Nutley',\n",
       " 'Of',\n",
       " 'Oh',\n",
       " 'On',\n",
       " 'Once',\n",
       " 'Only',\n",
       " 'Or',\n",
       " 'Perhaps',\n",
       " 'Poor',\n",
       " 'Professional',\n",
       " 'Renaissance',\n",
       " 'Rickham',\n",
       " 'Riviera',\n",
       " 'Rome',\n",
       " 'Russian',\n",
       " 'Sevres',\n",
       " 'She',\n",
       " 'Stroud',\n",
       " 'Strouds',\n",
       " 'Suddenly',\n",
       " 'That',\n",
       " 'The',\n",
       " 'Then',\n",
       " 'There',\n",
       " 'They',\n",
       " 'This',\n",
       " 'Those',\n",
       " 'Though',\n",
       " 'Thwing',\n",
       " 'Thwings',\n",
       " 'To',\n",
       " 'Usually',\n",
       " 'Venetian',\n",
       " 'Victor',\n",
       " 'Was',\n",
       " 'We',\n",
       " 'Well',\n",
       " 'What',\n",
       " 'When',\n",
       " 'Why',\n",
       " 'Yes',\n",
       " 'You',\n",
       " '_',\n",
       " 'a',\n",
       " 'abdication',\n",
       " 'able',\n",
       " 'about',\n",
       " 'above',\n",
       " 'abruptly',\n",
       " 'absolute',\n",
       " 'absorbed',\n",
       " 'absurdity',\n",
       " 'academic',\n",
       " 'accuse',\n",
       " 'accustomed',\n",
       " 'across',\n",
       " 'activity',\n",
       " 'add',\n",
       " 'added',\n",
       " 'admirers',\n",
       " 'adopted',\n",
       " 'adulation',\n",
       " 'advance',\n",
       " 'aesthetic',\n",
       " 'affect',\n",
       " 'afraid',\n",
       " 'after',\n",
       " 'afterward',\n",
       " 'again',\n",
       " 'ago',\n",
       " 'ah',\n",
       " 'air',\n",
       " 'alive',\n",
       " 'all',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'always',\n",
       " 'am',\n",
       " 'amazement',\n",
       " 'amid',\n",
       " 'among',\n",
       " 'amplest',\n",
       " 'amusing',\n",
       " 'an',\n",
       " 'and',\n",
       " 'another',\n",
       " 'answer',\n",
       " 'answered',\n",
       " 'any',\n",
       " 'anything',\n",
       " 'anywhere',\n",
       " 'apparent',\n",
       " 'apparently',\n",
       " 'appearance',\n",
       " 'appeared',\n",
       " 'appointed',\n",
       " 'are',\n",
       " 'arm',\n",
       " 'arm-chair',\n",
       " 'arm-chairs',\n",
       " 'arms',\n",
       " 'art',\n",
       " 'articles',\n",
       " 'artist',\n",
       " 'as',\n",
       " 'aside',\n",
       " 'asked',\n",
       " 'at',\n",
       " 'atmosphere',\n",
       " 'atom',\n",
       " 'attack',\n",
       " 'attention',\n",
       " 'attitude',\n",
       " 'audacities',\n",
       " 'away',\n",
       " 'awful',\n",
       " 'axioms',\n",
       " 'azaleas',\n",
       " 'back',\n",
       " 'background',\n",
       " 'balance',\n",
       " 'balancing',\n",
       " 'balustraded',\n",
       " 'basking',\n",
       " 'bath-rooms',\n",
       " 'be',\n",
       " 'beaming',\n",
       " 'bean-stalk',\n",
       " 'bear',\n",
       " 'beard',\n",
       " 'beauty',\n",
       " 'became',\n",
       " 'because',\n",
       " 'becoming',\n",
       " 'bed',\n",
       " 'been',\n",
       " 'before',\n",
       " 'began',\n",
       " 'begun',\n",
       " 'behind',\n",
       " 'being',\n",
       " 'believed',\n",
       " 'beneath',\n",
       " 'bespoke',\n",
       " 'better',\n",
       " 'between',\n",
       " 'big',\n",
       " 'bits',\n",
       " 'bitterness',\n",
       " 'blocked',\n",
       " 'born',\n",
       " 'borne',\n",
       " 'boudoir',\n",
       " 'bravura',\n",
       " 'break',\n",
       " 'breaking',\n",
       " 'breathing',\n",
       " 'bric-a-brac',\n",
       " 'briefly',\n",
       " 'brings',\n",
       " 'bronzes',\n",
       " 'brought',\n",
       " 'brown',\n",
       " 'brush',\n",
       " 'bull',\n",
       " 'business',\n",
       " 'but',\n",
       " 'buying',\n",
       " 'by',\n",
       " 'called',\n",
       " 'came',\n",
       " 'can',\n",
       " 'canvas',\n",
       " 'canvases',\n",
       " 'cards',\n",
       " 'care',\n",
       " 'career',\n",
       " 'caught',\n",
       " 'central',\n",
       " 'chair',\n",
       " 'chap',\n",
       " 'characteristic',\n",
       " 'charming',\n",
       " 'cheap',\n",
       " 'check',\n",
       " 'cheeks',\n",
       " 'chest',\n",
       " 'chimney-piece',\n",
       " 'chucked',\n",
       " 'cigar',\n",
       " 'cigarette',\n",
       " 'cigars',\n",
       " 'circulation',\n",
       " 'circumstance',\n",
       " 'circus-clown',\n",
       " 'claimed',\n",
       " 'clasping',\n",
       " 'clear',\n",
       " 'cleverer',\n",
       " 'close',\n",
       " 'clue',\n",
       " 'coat',\n",
       " 'collapsed',\n",
       " 'colour',\n",
       " 'come',\n",
       " 'comfortable',\n",
       " 'coming',\n",
       " 'companion',\n",
       " 'compared',\n",
       " 'complex',\n",
       " 'confident',\n",
       " 'congesting',\n",
       " 'conjugal',\n",
       " 'constraint',\n",
       " 'consummate',\n",
       " 'contended',\n",
       " 'continued',\n",
       " 'corner',\n",
       " 'corrected',\n",
       " 'could',\n",
       " 'couldn',\n",
       " 'count',\n",
       " 'countenance',\n",
       " 'couple',\n",
       " 'course',\n",
       " 'covered',\n",
       " 'craft',\n",
       " 'cried',\n",
       " 'crossed',\n",
       " 'crowned',\n",
       " 'crumbled',\n",
       " 'cry',\n",
       " 'cured',\n",
       " 'curiosity',\n",
       " 'curious',\n",
       " 'current',\n",
       " 'curtains',\n",
       " 'd',\n",
       " 'dabble',\n",
       " 'damask',\n",
       " 'dark',\n",
       " 'dashed',\n",
       " 'day',\n",
       " 'days',\n",
       " 'dead',\n",
       " 'deadening',\n",
       " 'dear',\n",
       " 'deep',\n",
       " 'deerhound',\n",
       " 'degree',\n",
       " 'delicate',\n",
       " 'demand',\n",
       " 'denied',\n",
       " 'deploring',\n",
       " 'deprecating',\n",
       " 'deprecatingly',\n",
       " 'desire',\n",
       " 'destroyed',\n",
       " 'destruction',\n",
       " 'desultory',\n",
       " 'detail',\n",
       " 'diagnosis',\n",
       " 'did',\n",
       " 'didn',\n",
       " 'died',\n",
       " 'dim',\n",
       " 'dimmest',\n",
       " 'dingy',\n",
       " 'dining-room',\n",
       " 'disarming',\n",
       " 'discovery',\n",
       " 'discrimination',\n",
       " 'discussion',\n",
       " 'disdain',\n",
       " 'disdained',\n",
       " 'disease',\n",
       " 'disguised',\n",
       " 'display',\n",
       " 'dissatisfied',\n",
       " 'distinguished',\n",
       " 'distract',\n",
       " 'divert',\n",
       " 'do',\n",
       " 'doesn',\n",
       " 'doing',\n",
       " 'domestic',\n",
       " 'don',\n",
       " 'done',\n",
       " 'donkey',\n",
       " 'down',\n",
       " 'dozen',\n",
       " 'dragged',\n",
       " 'drawing-room',\n",
       " 'drawing-rooms',\n",
       " 'drawn',\n",
       " 'dress-closets',\n",
       " 'drew',\n",
       " 'dropped',\n",
       " 'each',\n",
       " 'earth',\n",
       " 'ease',\n",
       " 'easel',\n",
       " 'easy',\n",
       " 'echoed',\n",
       " 'economy',\n",
       " 'effect',\n",
       " 'effects',\n",
       " 'efforts',\n",
       " 'egregious',\n",
       " 'eighteenth-century',\n",
       " 'elbow',\n",
       " 'elegant',\n",
       " 'else',\n",
       " 'embarrassed',\n",
       " 'enabled',\n",
       " 'end',\n",
       " 'endless',\n",
       " 'enjoy',\n",
       " 'enlightenment',\n",
       " 'enough',\n",
       " 'ensuing',\n",
       " 'equally',\n",
       " 'equanimity',\n",
       " 'escape',\n",
       " 'established',\n",
       " 'etching',\n",
       " 'even',\n",
       " 'event',\n",
       " 'ever',\n",
       " 'everlasting',\n",
       " 'every',\n",
       " 'exasperated',\n",
       " 'except',\n",
       " 'excuse',\n",
       " 'excusing',\n",
       " 'existed',\n",
       " 'expected',\n",
       " 'exquisite',\n",
       " 'exquisitely',\n",
       " 'extenuation',\n",
       " 'exterminating',\n",
       " 'extracting',\n",
       " 'eye',\n",
       " 'eyebrows',\n",
       " 'eyes',\n",
       " 'face',\n",
       " 'faces',\n",
       " 'fact',\n",
       " 'faded',\n",
       " 'failed',\n",
       " 'failure',\n",
       " 'fair',\n",
       " 'faith',\n",
       " 'false',\n",
       " 'familiar',\n",
       " 'famille-verte',\n",
       " 'fancy',\n",
       " 'fashionable',\n",
       " 'fate',\n",
       " 'feather',\n",
       " 'feet',\n",
       " 'fell',\n",
       " 'fellow',\n",
       " 'felt',\n",
       " 'few',\n",
       " 'fewer',\n",
       " 'finality',\n",
       " 'find',\n",
       " 'fingers',\n",
       " 'first',\n",
       " 'fit',\n",
       " 'fitting',\n",
       " 'five',\n",
       " 'flash',\n",
       " 'flashed',\n",
       " 'florid',\n",
       " 'flowers',\n",
       " 'fluently',\n",
       " 'flung',\n",
       " 'follow',\n",
       " 'followed',\n",
       " 'fond',\n",
       " 'footstep',\n",
       " 'for',\n",
       " 'forced',\n",
       " 'forcing',\n",
       " 'forehead',\n",
       " 'foreign',\n",
       " 'foreseen',\n",
       " 'forgive',\n",
       " 'forgotten',\n",
       " 'form',\n",
       " 'formed',\n",
       " 'forming',\n",
       " 'forward',\n",
       " 'fostered',\n",
       " 'found',\n",
       " 'foundations',\n",
       " 'fragment',\n",
       " 'fragments',\n",
       " 'frame',\n",
       " 'frames',\n",
       " 'frequently',\n",
       " 'friend',\n",
       " 'from',\n",
       " 'full',\n",
       " 'fullest',\n",
       " 'furiously',\n",
       " 'furrowed',\n",
       " 'garlanded',\n",
       " 'garlands',\n",
       " 'gave',\n",
       " 'genial',\n",
       " 'genius',\n",
       " 'gesture',\n",
       " 'get',\n",
       " 'getting',\n",
       " 'give',\n",
       " 'given',\n",
       " 'glad',\n",
       " 'glanced',\n",
       " 'glimpse',\n",
       " 'gloried',\n",
       " 'glory',\n",
       " 'go',\n",
       " 'going',\n",
       " 'gone',\n",
       " 'good',\n",
       " 'good-breeding',\n",
       " 'good-humoured',\n",
       " 'got',\n",
       " 'grace',\n",
       " 'gradually',\n",
       " 'gray',\n",
       " 'grayish',\n",
       " 'great',\n",
       " 'greatest',\n",
       " 'greatness',\n",
       " 'grew',\n",
       " 'groping',\n",
       " 'growing',\n",
       " 'had',\n",
       " 'hadn',\n",
       " 'hair',\n",
       " 'half',\n",
       " 'half-light',\n",
       " 'half-mechanically',\n",
       " 'hall',\n",
       " 'hand',\n",
       " 'hands',\n",
       " 'handsome',\n",
       " 'hanging',\n",
       " 'happen',\n",
       " 'happened',\n",
       " 'hard',\n",
       " 'hardly',\n",
       " 'has',\n",
       " 'have',\n",
       " 'haven',\n",
       " 'having',\n",
       " 'he',\n",
       " 'head',\n",
       " 'hear',\n",
       " 'heard',\n",
       " 'heart',\n",
       " 'height',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hermit',\n",
       " 'herself',\n",
       " 'hesitations',\n",
       " 'hide',\n",
       " 'high',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'hint',\n",
       " 'his',\n",
       " 'history',\n",
       " 'holding',\n",
       " 'home',\n",
       " 'honour',\n",
       " 'hooded',\n",
       " 'hostess',\n",
       " 'hot-house',\n",
       " 'hour',\n",
       " 'hours',\n",
       " 'house',\n",
       " 'how',\n",
       " 'hung',\n",
       " 'husband',\n",
       " 'idea',\n",
       " 'idle',\n",
       " 'idling',\n",
       " 'if',\n",
       " 'immediately',\n",
       " 'in',\n",
       " 'incense',\n",
       " 'indifferent',\n",
       " 'inevitable',\n",
       " 'inevitably',\n",
       " 'inflexible',\n",
       " 'insensible',\n",
       " 'insignificant',\n",
       " 'instinctively',\n",
       " 'instructive',\n",
       " 'interesting',\n",
       " 'into',\n",
       " 'ironic',\n",
       " 'irony',\n",
       " 'irrelevance',\n",
       " 'irrevocable',\n",
       " 'is',\n",
       " 'it',\n",
       " 'its',\n",
       " 'itself',\n",
       " 'jardiniere',\n",
       " 'jealousy',\n",
       " 'just',\n",
       " 'keep',\n",
       " 'kept',\n",
       " 'kind',\n",
       " 'knees',\n",
       " 'knew',\n",
       " 'know',\n",
       " 'known',\n",
       " 'laid',\n",
       " 'lair',\n",
       " 'landing',\n",
       " 'language',\n",
       " 'last',\n",
       " 'late',\n",
       " 'later',\n",
       " 'latter',\n",
       " 'laugh',\n",
       " 'laughed',\n",
       " 'lay',\n",
       " 'leading',\n",
       " 'lean',\n",
       " 'learned',\n",
       " 'least',\n",
       " 'leathery',\n",
       " 'leave',\n",
       " 'led',\n",
       " 'left',\n",
       " 'leisure',\n",
       " 'lends',\n",
       " 'lent',\n",
       " 'let',\n",
       " 'lies',\n",
       " 'life',\n",
       " 'life-likeness',\n",
       " 'lift',\n",
       " 'lifted',\n",
       " 'light',\n",
       " 'lightly',\n",
       " 'like',\n",
       " 'liked',\n",
       " 'line',\n",
       " 'lines',\n",
       " 'lingered',\n",
       " 'lips',\n",
       " 'lit',\n",
       " 'little',\n",
       " 'live',\n",
       " 'll',\n",
       " 'loathing',\n",
       " 'long',\n",
       " 'longed',\n",
       " 'longer',\n",
       " 'look',\n",
       " 'looked',\n",
       " 'looking',\n",
       " 'lose',\n",
       " 'loss',\n",
       " 'lounging',\n",
       " 'lovely',\n",
       " 'lucky',\n",
       " 'lump',\n",
       " 'luncheon-table',\n",
       " 'luxury',\n",
       " 'lying',\n",
       " 'made',\n",
       " 'make',\n",
       " 'man',\n",
       " 'manage',\n",
       " 'managed',\n",
       " 'mantel-piece',\n",
       " 'marble',\n",
       " 'married',\n",
       " 'may',\n",
       " 'me',\n",
       " 'meant',\n",
       " 'mediocrity',\n",
       " 'medium',\n",
       " 'mentioned',\n",
       " 'mere',\n",
       " 'merely',\n",
       " 'met',\n",
       " 'might',\n",
       " 'mighty',\n",
       " 'millionaire',\n",
       " 'mine',\n",
       " 'minute',\n",
       " 'minutes',\n",
       " 'mirrors',\n",
       " 'modest',\n",
       " 'modesty',\n",
       " 'moment',\n",
       " 'money',\n",
       " 'monumental',\n",
       " 'mood',\n",
       " 'morbidly',\n",
       " 'more',\n",
       " 'most',\n",
       " 'mourn',\n",
       " 'mourned',\n",
       " 'moustache',\n",
       " 'moved',\n",
       " 'much',\n",
       " 'muddling',\n",
       " 'multiplied',\n",
       " 'murmur',\n",
       " 'muscles',\n",
       " 'must',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'mysterious',\n",
       " 'naive',\n",
       " 'near',\n",
       " 'nearly',\n",
       " 'negatived',\n",
       " 'nervous',\n",
       " 'nervousness',\n",
       " 'neutral',\n",
       " 'never',\n",
       " 'next',\n",
       " 'no',\n",
       " 'none',\n",
       " 'not',\n",
       " 'note',\n",
       " 'nothing',\n",
       " 'now',\n",
       " 'nymphs',\n",
       " 'oak',\n",
       " 'obituary',\n",
       " 'object',\n",
       " 'objects',\n",
       " 'occurred',\n",
       " 'oddly',\n",
       " 'of',\n",
       " 'off',\n",
       " 'often',\n",
       " 'oh',\n",
       " 'old',\n",
       " 'on',\n",
       " 'once',\n",
       " 'one',\n",
       " 'ones',\n",
       " 'only',\n",
       " 'onto',\n",
       " 'open',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'outline',\n",
       " 'oval',\n",
       " 'over',\n",
       " 'own',\n",
       " 'packed',\n",
       " 'paid',\n",
       " 'paint',\n",
       " 'painted',\n",
       " 'painter',\n",
       " 'painting',\n",
       " 'pale',\n",
       " 'paled',\n",
       " 'palm-trees',\n",
       " 'panel',\n",
       " 'panelling',\n",
       " 'pardonable',\n",
       " 'pardoned',\n",
       " 'part',\n",
       " 'passages',\n",
       " 'passing',\n",
       " 'past',\n",
       " 'pastels',\n",
       " 'pathos',\n",
       " 'patient',\n",
       " 'people',\n",
       " 'perceptible',\n",
       " 'perfect',\n",
       " 'persistence',\n",
       " 'persuasively',\n",
       " 'phrase',\n",
       " 'picture',\n",
       " 'pictures',\n",
       " 'pines',\n",
       " 'pink',\n",
       " 'place',\n",
       " 'placed',\n",
       " 'plain',\n",
       " 'platitudes',\n",
       " 'pleased',\n",
       " 'pockets',\n",
       " 'point',\n",
       " 'poised',\n",
       " 'poor',\n",
       " 'portrait',\n",
       " 'posing',\n",
       " 'possessed',\n",
       " 'poverty',\n",
       " 'predicted',\n",
       " 'preliminary',\n",
       " 'presenting',\n",
       " 'prestidigitation',\n",
       " 'pretty',\n",
       " 'previous',\n",
       " 'price',\n",
       " 'pride',\n",
       " 'princely',\n",
       " 'prism',\n",
       " 'problem',\n",
       " 'proclaiming',\n",
       " 'prodigious',\n",
       " 'profusion',\n",
       " 'protest',\n",
       " 'prove',\n",
       " 'public',\n",
       " 'purblind',\n",
       " 'purely',\n",
       " 'pushed',\n",
       " 'put',\n",
       " 'qualities',\n",
       " 'quality',\n",
       " 'queerly',\n",
       " 'question',\n",
       " 'quickly',\n",
       " 'quietly',\n",
       " 'quite',\n",
       " 'quote',\n",
       " 'rain',\n",
       " 'raised',\n",
       " 'random',\n",
       " 'rather',\n",
       " 're',\n",
       " 'real',\n",
       " 'really',\n",
       " 'reared',\n",
       " 'reason',\n",
       " 'reassurance',\n",
       " 'recovering',\n",
       " 'recreated',\n",
       " 'reflected',\n",
       " 'reflection',\n",
       " 'regrets',\n",
       " 'relatively',\n",
       " 'remained',\n",
       " 'remember',\n",
       " 'reminded',\n",
       " 'repeating',\n",
       " 'represented',\n",
       " 'reproduction',\n",
       " 'resented',\n",
       " 'resolve',\n",
       " 'resources',\n",
       " 'rest',\n",
       " 'rich',\n",
       " 'ridiculous',\n",
       " 'robbed',\n",
       " 'romantic',\n",
       " 'room',\n",
       " 'rose',\n",
       " 'rs',\n",
       " 'rule',\n",
       " 'run',\n",
       " 's',\n",
       " 'said',\n",
       " 'same',\n",
       " 'satisfaction',\n",
       " 'savour',\n",
       " 'saw',\n",
       " 'say',\n",
       " 'saying',\n",
       " 'says',\n",
       " 'scorn',\n",
       " 'scornful',\n",
       " 'secret',\n",
       " 'see',\n",
       " 'seemed',\n",
       " 'seen',\n",
       " 'self-confident',\n",
       " 'send',\n",
       " 'sensation',\n",
       " 'sensitive',\n",
       " 'sent',\n",
       " 'serious',\n",
       " 'set',\n",
       " 'sex',\n",
       " 'shade',\n",
       " 'shaking',\n",
       " 'shall',\n",
       " 'she',\n",
       " 'shirked',\n",
       " 'short',\n",
       " 'should',\n",
       " 'shoulder',\n",
       " 'shoulders',\n",
       " 'show',\n",
       " 'showed',\n",
       " 'showy',\n",
       " 'shrug',\n",
       " 'shrugged',\n",
       " 'sight',\n",
       " 'sign',\n",
       " 'silent',\n",
       " 'silver',\n",
       " 'similar',\n",
       " 'simpleton',\n",
       " 'simplifications',\n",
       " 'simply',\n",
       " 'since',\n",
       " 'single',\n",
       " 'sitter',\n",
       " 'sitters',\n",
       " 'sketch',\n",
       " 'skill',\n",
       " 'slight',\n",
       " 'slightly',\n",
       " 'slowly',\n",
       " 'small',\n",
       " 'smile',\n",
       " 'smiling',\n",
       " 'sneer',\n",
       " 'so',\n",
       " 'solace',\n",
       " 'some',\n",
       " 'somebody',\n",
       " 'something',\n",
       " 'spacious',\n",
       " 'spaniel',\n",
       " 'speaking-tubes',\n",
       " 'speculations',\n",
       " 'spite',\n",
       " 'splash',\n",
       " 'square',\n",
       " 'stairs',\n",
       " 'stammer',\n",
       " 'stand',\n",
       " 'standing',\n",
       " 'started',\n",
       " 'stay',\n",
       " 'still',\n",
       " 'stocked',\n",
       " 'stood',\n",
       " 'stopped',\n",
       " 'stopping',\n",
       " 'straddling',\n",
       " 'straight',\n",
       " 'strain',\n",
       " 'straining',\n",
       " 'strange',\n",
       " 'straw',\n",
       " 'stream',\n",
       " 'stroke',\n",
       " 'strokes',\n",
       " 'strolled',\n",
       " 'strongest',\n",
       " 'strongly',\n",
       " 'struck',\n",
       " 'studio',\n",
       " 'stuff',\n",
       " 'subject',\n",
       " 'substantial',\n",
       " 'suburban',\n",
       " 'such',\n",
       " 'suddenly',\n",
       " 'suffered',\n",
       " 'sugar',\n",
       " 'suggested',\n",
       " 'sunburn',\n",
       " 'sunburnt',\n",
       " 'sunlit',\n",
       " 'superb',\n",
       " 'sure',\n",
       " 'surest',\n",
       " 'surface',\n",
       " 'surprise',\n",
       " 'surprised',\n",
       " 'surrounded',\n",
       " 'suspected',\n",
       " 'sweetly',\n",
       " 'sweetness',\n",
       " 'swelling',\n",
       " 'swept',\n",
       " 'swum',\n",
       " 't',\n",
       " 'table',\n",
       " 'take',\n",
       " 'taken',\n",
       " 'talking',\n",
       " 'tea',\n",
       " 'tears',\n",
       " 'technicalities',\n",
       " 'technique',\n",
       " 'tell',\n",
       " 'tells',\n",
       " 'tempting',\n",
       " 'terra-cotta',\n",
       " 'terrace',\n",
       " 'terraces',\n",
       " 'terribly',\n",
       " 'than',\n",
       " 'that',\n",
       " 'the',\n",
       " 'their',\n",
       " 'them',\n",
       " 'then',\n",
       " 'there',\n",
       " 'therefore',\n",
       " 'they',\n",
       " 'thin',\n",
       " 'thing',\n",
       " 'things',\n",
       " 'think',\n",
       " 'this',\n",
       " ...]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words = set(preprocessed)\n",
    "all_words = sorted(all_words)\n",
    "all_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python, `set` and `dict` are both built-in data structures, but they serve different purposes and have distinct characteristics:\n",
    "\n",
    "### Set\n",
    "- **Definition**: A `set` is an unordered collection of unique elements.\n",
    "- **Syntax**: Defined using curly braces `{}` or the `set()` function.\n",
    "  ```python\n",
    "  my_set = {1, 2, 3}\n",
    "  my_set = set([1, 2, 3])\n",
    "  ```\n",
    "- **Uniqueness**: Automatically removes duplicate elements.\n",
    "  ```python\n",
    "  my_set = {1, 2, 2, 3}  # Result: {1, 2, 3}\n",
    "  ```\n",
    "- **Mutability**: Sets are mutable; you can add or remove elements.\n",
    "  ```python\n",
    "  my_set.add(4)\n",
    "  my_set.remove(2)\n",
    "  ```\n",
    "- **Operations**: Supports mathematical set operations like union, intersection, difference.\n",
    "  ```python\n",
    "  set1 = {1, 2, 3}\n",
    "  set2 = {3, 4, 5}\n",
    "  union_set = set1 | set2  # {1, 2, 3, 4, 5}\n",
    "  intersection_set = set1 & set2  # {3}\n",
    "  ```\n",
    "\n",
    "### Dictionary\n",
    "- **Definition**: A `dict` (dictionary) is an unordered collection of key-value pairs.\n",
    "- **Syntax**: Defined using curly braces `{}` with key-value pairs or the `dict()` function.\n",
    "  ```python\n",
    "  my_dict = {'a': 1, 'b': 2, 'c': 3}\n",
    "  my_dict = dict(a=1, b=2, c=3)\n",
    "  ```\n",
    "- **Key-Value Pairs**: Each key is unique and maps to a value.\n",
    "  ```python\n",
    "  my_dict = {'a': 1, 'b': 2, 'b': 3}  # Result: {'a': 1, 'b': 3}\n",
    "  ```\n",
    "- **Mutability**: Dictionaries are mutable; you can add, remove, or modify key-value pairs.\n",
    "  ```python\n",
    "  my_dict['d'] = 4\n",
    "  del my_dict['a']\n",
    "  my_dict['b'] = 5\n",
    "  ```\n",
    "- **Access**: Values are accessed using keys.\n",
    "  ```python\n",
    "  value = my_dict['b']  # 5\n",
    "  ```\n",
    "\n",
    "### Summary\n",
    "- **Set**: Unordered collection of unique elements, used for membership testing and set operations.\n",
    "- **Dict**: Unordered collection of key-value pairs, used for fast lookups, additions, and deletions based on keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1130\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(all_words)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('!', 0)\n",
      "('\"', 1)\n",
      "(\"'\", 2)\n",
      "('(', 3)\n",
      "(')', 4)\n",
      "(',', 5)\n",
      "('--', 6)\n",
      "('.', 7)\n",
      "(':', 8)\n",
      "(';', 9)\n",
      "('?', 10)\n",
      "('A', 11)\n"
     ]
    }
   ],
   "source": [
    "vocab = {token: integer for integer, token in enumerate(all_words)}\n",
    "for i, item in enumerate(vocab.items()):\n",
    "    print(item)\n",
    "    if i > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTokenizerV1:\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = {integer: token for token, integer in vocab.items()}\n",
    "\n",
    "    def encode(self, text):\n",
    "        preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
    "        preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "        return [self.str_to_int[token] for token in preprocessed]\n",
    "    \n",
    "    def decode(self, ids):\n",
    "        text = \" \".join([self.int_to_str[id] for id in ids])\n",
    "        text = re.sub(r'\\s([,.:;?_!\"()\\']|--)', r'\\1', text) # remove space before punctuation\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 56, 2, 850, 988, 602, 533, 746, 5, 1126, 596, 5, 1, 67, 7, 38, 851, 1108, 754, 793, 7]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = SimpleTokenizerV1(vocab)\n",
    "text = \"\"\"\"It's the last he painted, you know,\"\n",
    "        Mrs. Gisburn said with pardonable pride.\"\"\"\n",
    "ids = tokenizer.encode(text)\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\" It' s the last he painted, you know,\" Mrs. Gisburn said with pardonable pride.\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Byte pairing encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "import tiktoken\n",
    "print(version(\"tiktoken\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15496, 11, 466, 345, 588, 8887, 30, 220, 50256, 3363, 11, 314, 466, 286, 617, 34680, 27271, 13]\n"
     ]
    }
   ],
   "source": [
    "text = (\"Hello, do you like tea? <|endoftext|> Yes, I do \"\n",
    "        \"of someunknownPlace.\")\n",
    "\n",
    "integers = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "print(integers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, do you like tea? <|endoftext|> Yes, I do of someunknownPlace.\n"
     ]
    }
   ],
   "source": [
    "strings = tokenizer.decode(integers)\n",
    "print(strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33901, 86, 343, 86, 220, 959]\n"
     ]
    }
   ],
   "source": [
    "exercise = \"Akwirw ier\"\n",
    "integers = tokenizer.encode(exercise)\n",
    "print(integers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akwirw ier\n"
     ]
    }
   ],
   "source": [
    "strings = tokenizer.decode(integers)\n",
    "print(strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5145\n"
     ]
    }
   ],
   "source": [
    "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "enc_text = tokenizer.encode(raw_text)\n",
    "print(len(enc_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[290, 4920, 2241, 287]\n",
      "[4920, 2241, 287, 257]\n"
     ]
    }
   ],
   "source": [
    "enc_sample = enc_text[50:]\n",
    "context_size = 4\n",
    "x = enc_sample[:context_size]\n",
    "y = enc_sample[1:context_size+1]\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[290] ----> 4920\n",
      " and ---->  established\n",
      "[290, 4920] ----> 2241\n",
      " and established ---->  himself\n",
      "[290, 4920, 2241] ----> 287\n",
      " and established himself ---->  in\n",
      "[290, 4920, 2241, 287] ----> 257\n",
      " and established himself in ---->  a\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, context_size+1):\n",
    "    context = enc_sample[:i]\n",
    "    target = enc_sample[i]\n",
    "    print(context, \"---->\", target)\n",
    "    context_words = tokenizer.decode(context)\n",
    "    target_word = tokenizer.decode([target])\n",
    "    print(context_words, \"---->\", target_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        token_ids = tokenizer.encode(txt)\n",
    "\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i:i+max_length]\n",
    "            target_chunk = token_ids[i+1:i+max_length+1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids) # total number of rows in the dataset\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx] # return a single row from the dataset\n",
    "    \n",
    "\n",
    "def create_dataloader_v1(txt, batch_size = 4, max_length = 256,\n",
    "                         stride = 128, shuffle = True, drop_last = True, num_workers = 0):\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "    dataloader  = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last, num_workers=num_workers)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[  40,  367, 2885, 1464]]), tensor([[ 367, 2885, 1464, 1807]])]\n"
     ]
    }
   ],
   "source": [
    "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "dataloader = create_dataloader_v1(raw_text, batch_size=1, max_length = 4, stride=1, shuffle = False)\n",
    "data_iter = iter(dataloader)\n",
    "first_batch = next(data_iter)\n",
    "print(first_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_batch[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[ 367, 2885, 1464, 1807]]), tensor([[2885, 1464, 1807, 3619]])]\n"
     ]
    }
   ],
   "source": [
    "second_batch = next(data_iter)\n",
    "print(second_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[ 40, 367]]), tensor([[ 367, 2885]])]\n",
      "[tensor([[2885, 1464]]), tensor([[1464, 1807]])]\n"
     ]
    }
   ],
   "source": [
    "dataloader_practice1 = create_dataloader_v1(raw_text, batch_size=1, max_length=2, stride=2, shuffle=False)\n",
    "data_iter = iter(dataloader_practice1)\n",
    "first_batch = next(data_iter)\n",
    "print(first_batch) # first tensor is the input_ids and the second tensor is the target_ids\n",
    "second_batch = next(data_iter)\n",
    "print(second_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[   40,   367,  2885,  1464,  1807,  3619,   402,   271],\n",
      "        [ 2885,  1464,  1807,  3619,   402,   271, 10899,  2138]]), tensor([[  367,  2885,  1464,  1807,  3619,   402,   271, 10899],\n",
      "        [ 1464,  1807,  3619,   402,   271, 10899,  2138,   257]])]\n",
      "[tensor([[ 1807,  3619,   402,   271, 10899,  2138,   257,  7026],\n",
      "        [  402,   271, 10899,  2138,   257,  7026, 15632,   438]]), tensor([[ 3619,   402,   271, 10899,  2138,   257,  7026, 15632],\n",
      "        [  271, 10899,  2138,   257,  7026, 15632,   438,  2016]])]\n"
     ]
    }
   ],
   "source": [
    "dataloader_practice1 = create_dataloader_v1(raw_text, batch_size=2, max_length=8, stride=2, shuffle=False)\n",
    "data_iter = iter(dataloader_practice1)\n",
    "first_batch = next(data_iter)\n",
    "print(first_batch) #  first tensor is the input_ids and the second tensor is the target_ids\n",
    "second_batch = next(data_iter)\n",
    "print(second_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create token embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.3374, -0.1778, -0.1690],\n",
      "        [ 0.9178,  1.5810,  1.3010],\n",
      "        [ 1.2753, -0.2010, -0.1606],\n",
      "        [-0.4015,  0.9666, -1.1481],\n",
      "        [-1.1589,  0.3255, -0.6315],\n",
      "        [-2.8400, -0.7849, -1.4096]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "input_ids = [2, 3, 5, 1]\n",
    "vocab_size = 6\n",
    "output_dim = 3\n",
    "\n",
    "torch.manual_seed(123)\n",
    "embedding_layer = torch.nn.Embedding(vocab_size, output_dim)\n",
    "print(embedding_layer.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4015,  0.9666, -1.1481], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_layer(torch.tensor(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.2753, -0.2010, -0.1606],\n",
      "        [-0.4015,  0.9666, -1.1481],\n",
      "        [-2.8400, -0.7849, -1.4096],\n",
      "        [ 0.9178,  1.5810,  1.3010]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_layer(torch.tensor(input_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 50257 # BPE tokenizer vocab size\n",
    "output_dim = 256 # embedding dimension\n",
    "token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [  922,  5891,  1576,   438],\n",
      "        [  568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502],\n",
      "        [  284,  3285,   326,    11]])\n",
      "\n",
      "Inputs shape: \n",
      " torch.Size([8, 4])\n"
     ]
    }
   ],
   "source": [
    "max_length = 4\n",
    "dataloader = create_dataloader_v1(raw_text, batch_size = 8, max_length = max_length, stride = max_length, shuffle=False)\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)\n",
    "print(\"Token IDs:\\n\", inputs)\n",
    "print(\"\\nInputs shape: \\n\", inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Token embeddings shape: \n",
      " torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "token_embeddings = token_embedding_layer(inputs)\n",
    "print(\"\\nToken embeddings shape: \\n\", token_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4913,  1.1239,  1.4588,  ..., -0.3995, -1.8735, -0.1445],\n",
       "        [ 0.4481,  0.2536, -0.2655,  ...,  0.4997, -1.1991, -1.1844],\n",
       "        [-0.2507, -0.0546,  0.6687,  ...,  0.9618,  2.3737, -0.0528],\n",
       "        [ 0.9457,  0.8657,  1.6191,  ..., -0.4544, -0.7460,  0.3483]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embeddings[0] # first batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 256])\n"
     ]
    }
   ],
   "source": [
    "print(token_embeddings[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 256])\n"
     ]
    }
   ],
   "source": [
    "context_length = max_length\n",
    "pos_embedding_layer = torch.nn.Embedding(context_length, output_dim)\n",
    "pos_embeddings = pos_embedding_layer(torch.arange(context_length))\n",
    "print(pos_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "input_embeddings = token_embeddings + pos_embeddings\n",
    "print(input_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
